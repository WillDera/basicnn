{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPI37nXF9BUqNrJRzKopcz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WillDera/simplenn/blob/master/Basic_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdBselDJZp2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12d98979-26d7-40e2-bce6-b78f63dc22b5"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "np.random.seed(1671) #for reproductivity"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pazFQjBvd04m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# network and training\n",
        "NB_EPOCH = 20\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10 # no. of outputs = no. of digits\n",
        "OPTIMIZER = Adam()\n",
        "N_HIDDEN = 128 \n",
        "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION\n",
        "DROPOUT = 0.3"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-ZIVAcNey0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data: shuffled and split b/w train and test sets\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# x_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784 \n",
        "RESHAPED = 784"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhEAaiqnfWyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(60000, RESHAPED)\n",
        "x_test = x_test.reshape(10000, RESHAPED)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tz5kJbPi51i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3be98098-e719-4adf-f602-88f20aec75b2"
      },
      "source": [
        "# normalize \n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVcWXJ8pjJRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHangYXajbaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0ea8ab9d-c31b-4dff-96ff-8c7aaa18735a"
      },
      "source": [
        "#10 outputs\n",
        "# final stage -> softmax\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(NB_CLASSES, input_shape=(RESHAPED,)))\n",
        "\n",
        "# adding a hidden layer and an activation function 'relu', to imporve our simple neural -> net.\n",
        "model.add(Activation('relu'))\n",
        "# adding the dropout regularization in order to try improving our Neural net.\n",
        "# model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "# another dropout regularizer\n",
        "# model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 10,548\n",
            "Trainable params: 10,548\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58hxGLl4kDP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compiling our model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzYjYj1RkXR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "2e17b9e1-9742-481b-fb53-b51c5219648a"
      },
      "source": [
        "# training our model\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.6679 - accuracy: 0.7939 - val_loss: 0.3113 - val_accuracy: 0.9082\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 1s 17us/step - loss: 0.2963 - accuracy: 0.9124 - val_loss: 0.2535 - val_accuracy: 0.9253\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.2475 - accuracy: 0.9278 - val_loss: 0.2308 - val_accuracy: 0.9297\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.2203 - accuracy: 0.9348 - val_loss: 0.2077 - val_accuracy: 0.9394\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.2023 - accuracy: 0.9403 - val_loss: 0.2095 - val_accuracy: 0.9373\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 1s 17us/step - loss: 0.1880 - accuracy: 0.9447 - val_loss: 0.1940 - val_accuracy: 0.9418\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.1767 - accuracy: 0.9485 - val_loss: 0.1796 - val_accuracy: 0.9482\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 1s 17us/step - loss: 0.1677 - accuracy: 0.9503 - val_loss: 0.1722 - val_accuracy: 0.9482\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.1596 - accuracy: 0.9522 - val_loss: 0.1751 - val_accuracy: 0.9488\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 1s 17us/step - loss: 0.1548 - accuracy: 0.9544 - val_loss: 0.1668 - val_accuracy: 0.9510\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.1477 - accuracy: 0.9556 - val_loss: 0.1668 - val_accuracy: 0.9519\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.1424 - accuracy: 0.9577 - val_loss: 0.1601 - val_accuracy: 0.9535\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.1374 - accuracy: 0.9593 - val_loss: 0.1642 - val_accuracy: 0.9530\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.1334 - accuracy: 0.9604 - val_loss: 0.1571 - val_accuracy: 0.9551\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 1s 17us/step - loss: 0.1290 - accuracy: 0.9619 - val_loss: 0.1526 - val_accuracy: 0.9563\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.1256 - accuracy: 0.9626 - val_loss: 0.1528 - val_accuracy: 0.9549\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.1225 - accuracy: 0.9641 - val_loss: 0.1612 - val_accuracy: 0.9535\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.1200 - accuracy: 0.9637 - val_loss: 0.1543 - val_accuracy: 0.9542\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.1167 - accuracy: 0.9645 - val_loss: 0.1519 - val_accuracy: 0.9577\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.1134 - accuracy: 0.9663 - val_loss: 0.1562 - val_accuracy: 0.9555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljMIqncYko9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6c526f26-24ca-4ca3-d378-71c33569e049"
      },
      "source": [
        "# evaluating our model\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=VERBOSE)\n",
        "print(\"Test Score: \", score[0])\n",
        "print(\"Test Accuracy: \", score[1])\n",
        "\n",
        "# values with just 1 hidden layer\n",
        "# Test Score:  0.2773810000360012\n",
        "# Test Accuracy:  0.9225000143051147\n",
        "\n",
        "# values after trying adding an additional hidden layer and the relu activation function\n",
        "# Test Score:  0.15192453786525875\n",
        "# Test Accuracy:  0.9555000066757202\n",
        "\n",
        "# value after trying out the dropout regularizer\n",
        "# Test Score:  0.36275843107700345\n",
        "# Test Accuracy:  0.899399995803833\n",
        "\n",
        "# values after trying the Adam optimizer without the dropout at 200epochs\n",
        "# Test Score:  0.3812370401768699\n",
        "# Test Accuracy:  0.9492999911308289\n",
        "\n",
        "# values after trying the Adam optimizer without the dropout at 20epochs\n",
        "# Test Score:  0.1615734796155244\n",
        "# Test Accuracy:  0.9545000195503235"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 21us/step\n",
            "Test Score:  0.1615734796155244\n",
            "Test Accuracy:  0.9545000195503235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy2OnMBgl_H5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding the dropout to our model depleted its performance on the test, train and validation data, we can try increasing the \n",
        "# number of epochs to see if there's any form of improvement."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}