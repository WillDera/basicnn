{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNI4sJgFA8QDHxOhgQiLTTh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WillDera/simplenn/blob/master/Basic_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdBselDJZp2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "np.random.seed(1671) #for reproductivity"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pazFQjBvd04m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# network and training\n",
        "NB_EPOCH = 20\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10 # no. of outputs = no. of digits\n",
        "OPTIMIZER = Adam()\n",
        "N_HIDDEN = 128 \n",
        "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION\n",
        "DROPOUT = 0.3"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-ZIVAcNey0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data: shuffled and split b/w train and test sets\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# x_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784 \n",
        "RESHAPED = 784"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhEAaiqnfWyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(60000, RESHAPED)\n",
        "x_test = x_test.reshape(10000, RESHAPED)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tz5kJbPi51i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9341be51-7c8a-4ecf-8e80-75648cca8d8d"
      },
      "source": [
        "# normalize \n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVcWXJ8pjJRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHangYXajbaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e87f0394-434c-4ada-8cd6-099c056f29d5"
      },
      "source": [
        "#10 outputs\n",
        "# final stage -> softmax\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "\n",
        "# adding a hidden layer and an activation function 'relu', to imporve our simple neural -> net.\n",
        "model.add(Activation('relu'))\n",
        "# adding the dropout regularization in order to try improving our Neural net.\n",
        "# model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "# another dropout regularizer\n",
        "# model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58hxGLl4kDP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compiling our model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzYjYj1RkXR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "66ecdb94-e7b5-4d7b-e644-e75e87ae8d44"
      },
      "source": [
        "# training our model\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3568 - accuracy: 0.8972 - val_loss: 0.1817 - val_accuracy: 0.9477\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1431 - accuracy: 0.9584 - val_loss: 0.1379 - val_accuracy: 0.9606\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0985 - accuracy: 0.9707 - val_loss: 0.1066 - val_accuracy: 0.9685\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0724 - accuracy: 0.9785 - val_loss: 0.1029 - val_accuracy: 0.9703\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0572 - accuracy: 0.9827 - val_loss: 0.0948 - val_accuracy: 0.9715\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.0966 - val_accuracy: 0.9725\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0369 - accuracy: 0.9888 - val_loss: 0.1004 - val_accuracy: 0.9693\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0289 - accuracy: 0.9914 - val_loss: 0.0900 - val_accuracy: 0.9736\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.0940 - val_accuracy: 0.9749\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.1059 - val_accuracy: 0.9722\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.1011 - val_accuracy: 0.9743\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.1003 - val_accuracy: 0.9747\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.1146 - val_accuracy: 0.9737\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.1168 - val_accuracy: 0.9728\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.1121 - val_accuracy: 0.9768\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.1215 - val_accuracy: 0.9765\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1225 - val_accuracy: 0.9761\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.1267 - val_accuracy: 0.9744\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.1418 - val_accuracy: 0.9745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljMIqncYko9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2bb75158-09f8-4114-b900-04f3c0a4efd7"
      },
      "source": [
        "# evaluating our model\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=VERBOSE)\n",
        "print(\"Test Score: \", score[0])\n",
        "print(\"Test Accuracy: \", score[1])\n",
        "\n",
        "# values with just 1 hidden layer\n",
        "# Test Score:  0.2773810000360012\n",
        "# Test Accuracy:  0.9225000143051147\n",
        "\n",
        "# values after trying adding an additional hidden layer and the relu activation function\n",
        "# Test Score:  0.15192453786525875\n",
        "# Test Accuracy:  0.9555000066757202\n",
        "\n",
        "# value after trying out the dropout regularizer\n",
        "# Test Score:  0.36275843107700345\n",
        "# Test Accuracy:  0.899399995803833\n",
        "\n",
        "# values after trying the Adam optimizer without the dropout at 200epochs\n",
        "# Test Score:  0.3812370401768699\n",
        "# Test Accuracy:  0.9492999911308289\n",
        "\n",
        "# values after trying the Adam optimizer without the dropout at 20epochs\n",
        "# Test Score:  0.1262009383630967\n",
        "# Test Accuracy: 0.9750999808311462"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 24us/step\n",
            "Test Score:  0.1262009383630967\n",
            "Test Accuracy:  0.9750999808311462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy2OnMBgl_H5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "7e580a3a-2b2f-4e12-b56d-65223b492e39"
      },
      "source": [
        "# make predictions\n",
        "predictions = model.predict(y_test)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-9a8bfb30e0e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_10_input to have shape (784,) but got array with shape (10,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UroaT-WAAh6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}